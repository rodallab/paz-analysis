# -*- coding: utf-8 -*-
"""
Created on Thu Aug 12 18:35:46 2021

@author: Steve
"""


# Iterate through csv files
# For each csv file, channel xy and NMJ xys
# create alpha mask with NMJxys
# For each channel and paired fake data, measure k and g
# aggregate across channels for each folder and create graph

import csv
import numpy as np
import os
from pathlib import Path
import matplotlib
import matplotlib.pyplot as plt
import libpysal
import numba
import pointpats as pp
import importlib

PATH='test'
COLORS=['g', 'm', 'k', 'c']
SPOTS=['.', '+', 'x']
SCALE=23.5641
DTRANSFORM=False   #whether to transform d values by multiplying by density prior to averaging
#CHANS=["Dyn", "BRP", "Nwk"]

class MaternPointProcess(pp.PointProcess):
    """
    """

    
    def __init__(self, window, n, samples, keep=False,
                 asPP=False, conditioning=False):
        self.window = window
        self.n = n
        self.scale = 1 # scaling to create buffer to manage edge effects
        self.samples = samples
        self.parents = 2*n*self.scale*self.scale
        self.conditioning = conditioning
        
        lam = self.parents/window.area
        d = np.sqrt(1.594/lam/np.pi)
        self.radius = d
        self.keep = keep
        self.realizations = {}
        self.setup()
        for sample in range(samples):
            self.realizations[sample] = self.draw(self.parameters[sample])
        if asPP:
            for sample in self.realizations:
                points = self.realizations[sample]
                self.realizations[sample] = pp.PointPattern(points, window=self.window)


    def setup(self):
        """
        Generate the number of events for each realization. If
        "conditioning" is False, all the event numbers are the same;
        if it is True, the number of parents is a random variable
        following a Poisson distribution, resulting in varied number
        of events.

        """

        self.parameters = {}
        self.num_parents = {}
        if self.conditioning:
            lambdas = poisson(self.parents, self.samples)
            for i, l in enumerate(lambdas):
                num = l * self.children
                self.parameters[i] = {'n': num}
                self.num_parents[i] = l
        else:
            for i in range(self.samples):
                self.parameters[i] = {'n': self.n}
                self.num_parents[i] = self.parents

    def draw(self, parameter):
        """
        Generate a series of point coordinates within the given window.

        Parameters
        ----------
        parameter  : dictionary
                     Key: 'n'.
                     Value: size of the realization.

        Returns
        -------
                   : array
                     A series of point coordinates.

        """
        c = 0
        sample = []
        n = parameter['n']
        while c < n:
            pnts = self.realize(n)
            pnts = [libpysal.cg.shapes.Point((x, y)) for x, y in pnts]
            pins = self.window.filter_contained(pnts)
            
            # repeat thinning on extended sample
            sample.extend(pins)
            revpnts = self.matII(np.array(sample).T)
            revpnts = [libpysal.cg.shapes.Point((x, y)) for x, y in revpnts]
            c = len(revpnts)
        return np.array([np.asarray(p) for p in revpnts[:n]])

    def realize(self, n):

        l, b, r, t = self.window.bbox
        x_buffer = int((r-l)*(self.scale-1)/2)
        y_buffer = int((t-b)*(self.scale-1)/2)
        nparents = int(2*n*self.scale*self.scale)
        
        # get parent points
        pxs = np.random.uniform(l-x_buffer, r+x_buffer, (nparents))
        pys = np.random.uniform(b-y_buffer, t+y_buffer, (nparents))
        pxy = np.array((pxs, pys))
        points = self.matII(pxy)
        return points
        
           
    def matII(self, points):
        # Thin according to Matern II process
        npoints = points[0].size
        ages = np.random.uniform(size=npoints)
        cents = np.array((points[0], points[1], ages))
        keep=np.zeros(npoints, dtype=bool)
        for ix in range(npoints):
            # return distance between each parent point ix and all other points
            distances=np.array([np.hypot(cents[0][ix]-cents[0][comp], cents[1][ix]-cents[1][comp]) for comp in range(npoints)])

            #check whether each point is inside the disc (but not the parent)
            inDisc=(distances<self.radius)&(distances>0)
            #get the age of the youngest point
            if(np.count_nonzero(inDisc)>0):
                youngest=np.min(cents[2][inDisc])
                if(cents[2][ix]<youngest):
                    keep[ix]=True
            else: keep[ix]=True
        keepers = cents[:2, keep]
        points=[(keepers[0][i], keepers[1][i]) for i in range(len(keepers[0]))]
        return points


def importData(fn):
    ''' 
    imports data from _centroids.csv file generated by PAZ analysis macro
    Expects 2*nChannels columns of local min/max centroid data followed
    by 2*nChannels columns of centroid data.
    Returns tuple of min/max and centroid coordinate lists
    '''
    mcent={}
    gcent={}
    with open(fn) as csvfile:
        csvr = csv.reader(csvfile, quotechar='|')
        header=next(csvr)
        # number of channels=(len(header))/4 
        # min/max and geometric centroid x and y for each channel  
        # last two columns are the NMJ coordinates
        table=np.array([row for row in csvr])
            
    
    chans=[header[i].split('_')[1] for i in range(0, int(len(header)/2), 2)]
    
    for c,chan in enumerate(chans):
        mcent[chan]=np.array([[row[2*c], row[2*c+1]] 
                              for row in table 
                              if row[2*c]!='NaN'], 
                             dtype=float)
        
        gcent[chan]=np.array([[row[2*len(chans)+2*c], row[2*len(chans)+2*c+1]] 
                              for row in table 
                              if row[2*len(chans)+2*c]!='NaN'], 
                             dtype=float)
    
    
    return (mcent, gcent)


def makeWindow(shape):
    alphaVerts=list(shape.exterior.coords)
    alphaVerts=[libpysal.cg.Point(p) for p in alphaVerts]
    alphaPoly=libpysal.cg.Polygon(alphaVerts)
    win=pp.Window(alphaPoly.parts)
    return win


def plotCentroids(centroids, mask=None, savepath=None):
    
        
    f,ax=plt.subplots(1,1)
    if(mask):
        ax.add_patch(
        PolygonPatch(
            mask,
            edgecolor='powderblue',
            facecolor='powderblue',
            alpha=.4,
            label='alpha shape'
        ))
    
    for i, (chan, cent) in enumerate(centroids.items()):
        col=i % len(COLORS)
        mark=i // len(COLORS)
        ax.scatter(cent[:,0],
                   cent[:,1], 
                   color=COLORS[col], 
                   marker=SPOTS[mark], 
                   label='{}'.format(chan)
                   )
        
    plt.legend()
   
    if(savepath):
        plt.savefig(os.path.join(savepath, "CentroidPositions.svg"), dpi=None)
    else:
        plt.show()
        
def plotG(obs, chan, pois=None, clust=None, spaced=None, savepath=None, flag=""):
    
    ax=plt.subplot()
    ax.plot(obs.d, obs.G, label = '{}'.format(chan), color='black', linewidth=2)
    
    if(pois):
        ax.plot(pois.d, pois.G, color='darkgray', linewidth=2, 
             label='Poisson')
    
    if(clust):
        ax.plot(clust.d, clust.G, color='magenta', linewidth=2, linestyle=(0, (5, 10)), label='Clustered')
        
    if(spaced):
        ax.plot(spaced.d, spaced.G, color='magenta', linewidth=2, label='Spaced')
    plt.legend()
    
    if(savepath):
        plt.savefig(os.path.join(savepath, "{}-{}_gd.svg".format(chan, flag)), dpi=None, facecolor='w', edgecolor='w')
    else:
        plt.show()


def analyzeCentroidFile(file, exp="NA", n=1):
    filename = file.split("\\")[-1]
    table=pd.read_csv(file)
    table.columns = table.columns.str.split("_", expand=True)
    chans = list(set(table.columns.get_level_values(0)))
    # Combine centroids into one list to make alpha shape that describes them cumulatively
    allcents = table.unstack()\
        .unstack(level=1)\
        .reset_index()\
        .drop(["level_0", "level_1"], axis=1)\
        .dropna()
    
    # Get merged alpha shape
    alpha_shape=libpysal.cg.alpha_shape_auto(allcents.to_numpy())
    win = makeWindow(alpha_shape)
    allgs={}
    for c in chans:
        N = table[c].dropna().size//2
        obs = pp.PointPattern(table[c].dropna().to_numpy())
        poisson = pp.PoissonPointProcess(win, N, 1, asPP=True).realizations[0]
        matern = MaternPointProcess(win, N, 1, asPP=True).realizations[0]
        clustered = pp.PoissonClusterPointProcess(win, 
                                              N, 
                                              N/5, 
                                              3, 
                                              1, 
                                              asPP=True
                                              ).realizations[0]
        obsg = pp.G(obs, 40)._stat
        poisg = pp.G(poisson, 40)._stat
        materng = pp.G(matern, 40)._stat
        clustg = pp.G(clustered, 40)._stat
        
        dists = {"obs":obsg, "poisson":poisg, "spaced":materng, "clustered":clustg}
        
        # Make a dictionary where each key is a "EXP_CHAN_TYPE_N" string
        
        gs = {f"{exp}_{c}_{key}_{n}":val for key, val in dists.items()}
        allgs.update(gs)
        
    return pd.DataFrame(allgs)


def analyzeCentroidFolder(root_dir, version=216):
    g_dfs=[]
    # Get all folders containing centroid data
    if(root_dir[-1] != os.path.sep):
        root_dir += os.path.sep
    exp_dirs = glob.glob(root_dir+"*/")
    centroid_dirs = glob.glob(os.path.join(root_dir,"*/", f"*V{version}*/", "*Centroid*/"))
    
    # For each Experiment folder containing centroid data, iterate over csv files and analyze
    print("Running:")
    for c_dir in centroid_dirs:
        files = glob.glob(os.path.join(c_dir, "*.csv"))
        exp = c_dir.split("\\")[-2].split("_")[0]
        for n, file in enumerate(files):
            g_dfs.append(analyzeCentroidFile(file, exp=exp, n=n))
            if (1+n)%25 == 0: print('*')
            else: print('*', end='')
    return pd.concat(g_dfs, axis=1)

def organizeCentroidData(df):
    ''' Take the output dataframe of analyzeCentroidFolder and organize/prep for plotting:
    1. Create multi-index from compound column headings
    2. Average individual images
    3. clean up rogue columns
    4. Melt to d (index), channel (Chan), and data type (Type)'''
       
    df.columns = df.columns.str.split("_", expand=True)
    if ('Unnamed: 0', np.nan, np.nan,  np.nan) in df.columns:
        df = df.drop(('Unnamed: 0', np.nan, np.nan,  np.nan), axis=1).reset_index(col_level=3)
    else: df.reset_index(col_level=3)
    df.columns.names = ["Exp", "Chan", "Type", "N"]
    allCentGroup = df.groupby(axis=1, level=[1,2]).mean()
    allCentGroup = allCentGroup.drop(('', ''), axis=1)
    allCentMelt = allCentGroup.reset_index().melt(id_vars = 'index')
    return allCentMelt


def plotOverallMean(df, savepath=None):
    sns.lineplot(data=df, x='index', y="value", hue="Type", ci="sd")
    if savepath:
        plt.savefig(savepath)


def plotIndividualChannels(df, savepath=None):
    # Plot one graph for each channel
    #chans = list(set(df.Chan))
    chans = ["BRP", "CLC", "DAP160", "NWK", "DYN", "FASII"]
    rows, cols = 3,3
    fig, axes = plt.subplots(rows, cols)
    fig.suptitle("Centroid Spatial Patterning", fontsize=11)
    plt.tight_layout()
    ax_i=0
    for row in range(rows):
        for col in range(cols):
            if ax_i<len(chans):
                ax=axes[row, col]
                show = chans[ax_i]
                sns.lineplot(data=df.loc[df.Chan==show, :], x="index", y="value", hue="Type", 
                                ci="sd", ax=ax)
                ax.set_ylabel("")
                ax.set_xlabel("")
                ax.set_title(chans[ax_i])
                ax.tick_params(axis='x', bottom=False, labelbottom=False)
                ax.tick_params(axis='y', labelsize=10)
                handles, labels = ax.get_legend_handles_labels()
                ax.get_legend().remove()
                ax_i+=1
    plt.figlegend(handles, labels, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)

    while ax_i < rows*cols:
        ax=axes[ax_i//cols, ax_i%cols]
        fig.delaxes(ax)
        ax_i+=1
    
    if savepath:
        plt.savefig(savepath)